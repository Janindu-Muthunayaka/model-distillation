{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOwyIedmVH1VZXYG4Db+hps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janindu-Muthunayaka/model-distillation/blob/main/Regressionv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports and DataSet"
      ],
      "metadata": {
        "id": "6bvDEfzMY9ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "# Data Preparation\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "X_House = housing.data\n",
        "Y_House = housing.target\n",
        "\n",
        "xTrain, xTest, yTrain, yTest = train_test_split(\n",
        "    X_House, Y_House, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "xTrain = scaler.fit_transform(xTrain)\n",
        "xTest = scaler.transform(xTest)\n",
        "\n",
        "xTrain = torch.tensor(xTrain, dtype=torch.float32)\n",
        "yTrain = torch.tensor(yTrain.values, dtype=torch.float32).view(-1, 1)\n",
        "xTest = torch.tensor(xTest, dtype=torch.float32)\n",
        "yTest = torch.tensor(yTest.values, dtype=torch.float32).view(-1, 1)\n"
      ],
      "metadata": {
        "id": "25qgUWvcYn2g"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teacher Model"
      ],
      "metadata": {
        "id": "Y9HB8G27YdDd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W8QjmzwVqp0s",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774d34ea-5cc5-4394-d9e1-9a75c165a4c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 3.6716\n",
            "Epoch [20/100], Loss: 1.6253\n",
            "Epoch [30/100], Loss: 0.8546\n",
            "Epoch [40/100], Loss: 0.7525\n",
            "Epoch [50/100], Loss: 0.6494\n",
            "Epoch [60/100], Loss: 0.5904\n",
            "Epoch [70/100], Loss: 0.5308\n",
            "Epoch [80/100], Loss: 0.4826\n",
            "Epoch [90/100], Loss: 0.4475\n",
            "Epoch [100/100], Loss: 0.4226\n"
          ]
        }
      ],
      "source": [
        "# Teacher Model (significantly larger)\n",
        "class HouseTeacher(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HouseTeacher, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = F.relu(self.fc5(x))\n",
        "        x = self.fc6(x)\n",
        "        return x\n",
        "\n",
        "teacher = HouseTeacher()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(teacher.parameters(), lr=0.001)\n",
        "epochs_teacher = 100  # More epochs for Teacher to exaggerate performance gaps\n",
        "\n",
        "for epoch in range(epochs_teacher):\n",
        "    teacher.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = teacher(xTrain)\n",
        "    loss = criterion(outputs, yTrain)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs_teacher}], Loss: {loss.item():.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Student Model"
      ],
      "metadata": {
        "id": "-vz80kdSYVul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Student Model\n",
        "class HouseStudent(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HouseStudent, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def distillation_loss_regression(student_out, teacher_out, true_labels, alpha=0.5):\n",
        "    hard_loss = F.mse_loss(student_out, true_labels)\n",
        "    soft_loss = F.mse_loss(student_out, teacher_out)\n",
        "    return alpha * hard_loss + (1 - alpha) * soft_loss\n",
        "\n",
        "student = HouseStudent()\n",
        "optimizer_s = optim.Adam(student.parameters(), lr=0.001)\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    student.train()\n",
        "    optimizer_s.zero_grad()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        teacher_outputs = teacher(xTrain)\n",
        "\n",
        "    student_outputs = student(xTrain)\n",
        "\n",
        "    loss = distillation_loss_regression(student_outputs, teacher_outputs, yTrain)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer_s.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], KD Loss: {loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9IwL28_YZ0B",
        "outputId": "9ccffbd8-fa11-43dc-e1f6-3181c3a229c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], KD Loss: 3.7540\n",
            "Epoch [20/100], KD Loss: 3.5454\n",
            "Epoch [30/100], KD Loss: 3.3300\n",
            "Epoch [40/100], KD Loss: 3.0981\n",
            "Epoch [50/100], KD Loss: 2.8486\n",
            "Epoch [60/100], KD Loss: 2.5852\n",
            "Epoch [70/100], KD Loss: 2.3117\n",
            "Epoch [80/100], KD Loss: 2.0335\n",
            "Epoch [90/100], KD Loss: 1.7563\n",
            "Epoch [100/100], KD Loss: 1.4864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Person Model"
      ],
      "metadata": {
        "id": "TFNAod_7YMAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Person Model (same architecture as Student, trained directly)\n",
        "class HousePerson(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HousePerson, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "person = HousePerson()\n",
        "optimizer_p = optim.Adam(person.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    person.train()\n",
        "    optimizer_p.zero_grad()\n",
        "    outputs = person(xTrain)\n",
        "    loss = criterion(outputs, yTrain)\n",
        "    loss.backward()\n",
        "    optimizer_p.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Person Loss: {loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjmX0sp9YOvL",
        "outputId": "c156ef16-c65d-4324-e535-9452733b1b43"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Person Loss: 4.6827\n",
            "Epoch [20/100], Person Loss: 4.4368\n",
            "Epoch [30/100], Person Loss: 4.1744\n",
            "Epoch [40/100], Person Loss: 3.8878\n",
            "Epoch [50/100], Person Loss: 3.5766\n",
            "Epoch [60/100], Person Loss: 3.2454\n",
            "Epoch [70/100], Person Loss: 2.9024\n",
            "Epoch [80/100], Person Loss: 2.5614\n",
            "Epoch [90/100], Person Loss: 2.2376\n",
            "Epoch [100/100], Person Loss: 1.9443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation Functions"
      ],
      "metadata": {
        "id": "iqIwvEhYYCmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_rmse(model, xTest, yTest):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(xTest)\n",
        "        mse = F.mse_loss(y_pred, yTest)\n",
        "        rmse = torch.sqrt(mse).item()\n",
        "    return rmse\n",
        "\n",
        "def evaluate_inference_time(model, xTest):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        start_time = time.time()\n",
        "        _ = model(xTest)\n",
        "        end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    avg_time = elapsed_time / xTest.size(0)\n",
        "    return elapsed_time, avg_time\n",
        "\n",
        "def evaluate_model_size(model):\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    param_size_MB = num_params * 4 / (1024**2)\n",
        "    return num_params, param_size_MB"
      ],
      "metadata": {
        "id": "fYv2wb6dYCCg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evalautions and Output Direct"
      ],
      "metadata": {
        "id": "sT3uR5V6X9IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "teacher_rmse = evaluate_rmse(teacher, xTest, yTest)\n",
        "teacher_time, teacher_avg_time = evaluate_inference_time(teacher, xTest)\n",
        "teacher_params, teacher_size = evaluate_model_size(teacher)\n",
        "\n",
        "student_rmse = evaluate_rmse(student, xTest, yTest)\n",
        "student_time, student_avg_time = evaluate_inference_time(student, xTest)\n",
        "student_params, student_size = evaluate_model_size(student)\n",
        "\n",
        "person_rmse = evaluate_rmse(person, xTest, yTest)\n",
        "person_time, person_avg_time = evaluate_inference_time(person, xTest)\n",
        "person_params, person_size = evaluate_model_size(person)\n",
        "\n",
        "# Teacher stats\n",
        "print(f\"Teacher RMSE: {teacher_rmse:.4f}\")\n",
        "print(f\"Teacher Inference Time: {teacher_time:.6f}s ({teacher_avg_time:.6f}s per sample)\")\n",
        "print(f\"Teacher Params: {teacher_params}, Size: {teacher_size:.6f} MB\")\n",
        "\n",
        "# Student stats\n",
        "print(f\"Student RMSE: {student_rmse:.4f}\")\n",
        "print(f\"Student Inference Time: {student_time:.6f}s ({student_avg_time:.6f}s per sample)\")\n",
        "print(f\"Student Params: {student_params}, Size: {student_size:.6f} MB\")\n",
        "\n",
        "# Person stats\n",
        "print(f\"Person RMSE: {person_rmse:.4f}\")\n",
        "print(f\"Person Inference Time: {person_time:.6f}s ({person_avg_time:.6f}s per sample)\")\n",
        "print(f\"Person Params: {person_params}, Size: {person_size:.6f} MB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFcN95v1X22U",
        "outputId": "c0fd9136-b1e2-457f-f88c-99347718592c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teacher RMSE: 0.6593\n",
            "Teacher Inference Time: 0.031752s (0.000008s per sample)\n",
            "Teacher Params: 179201, Size: 0.683598 MB\n",
            "Student RMSE: 1.2920\n",
            "Student Inference Time: 0.000346s (0.000000s per sample)\n",
            "Student Params: 289, Size: 0.001102 MB\n",
            "Person RMSE: 1.3714\n",
            "Person Inference Time: 0.000286s (0.000000s per sample)\n",
            "Person Params: 289, Size: 0.001102 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Results Percentage Comparisms"
      ],
      "metadata": {
        "id": "rnJyw4Ej4EGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Student vs Teacher percentages\n",
        "def percent_change(student_val, teacher_val):\n",
        "    return ((student_val - teacher_val) / teacher_val) * 100 if teacher_val != 0 else float('inf')\n",
        "\n",
        "print(\"\\n--- Percentage Change (Student vs Teacher) ---\")\n",
        "print(f\"RMSE Change: {percent_change(student_rmse, teacher_rmse):.2f}%\")\n",
        "print(f\"Total Inference Time Change: {percent_change(student_time, teacher_time):.2f}%\")\n",
        "print(f\"Avg Inference Time per Sample Change: {percent_change(student_avg_time, teacher_avg_time):.2f}%\")\n",
        "print(f\"Params Change: {percent_change(student_params, teacher_params):.2f}%\")\n",
        "print(f\"Model Size Change: {percent_change(student_size, teacher_size):.2f}%\")\n",
        "\n",
        "# Person vs Teacher percentages\n",
        "print(\"\\n--- Percentage Change (Person vs Teacher) ---\")\n",
        "print(f\"RMSE Change: {percent_change(person_rmse, teacher_rmse):.2f}%\")\n",
        "print(f\"Total Inference Time Change: {percent_change(person_time, teacher_time):.2f}%\")\n",
        "print(f\"Avg Inference Time per Sample Change: {percent_change(person_avg_time, teacher_avg_time):.2f}%\")\n",
        "print(f\"Params Change: {percent_change(person_params, teacher_params):.2f}%\")\n",
        "print(f\"Model Size Change: {percent_change(person_size, teacher_size):.2f}%\")"
      ],
      "metadata": {
        "id": "ud3FMuE44LVj",
        "outputId": "bd5db26e-e933-4ff3-c675-8bf31bedf21e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Percentage Change (Student vs Teacher) ---\n",
            "RMSE Change: 95.96%\n",
            "Total Inference Time Change: -98.91%\n",
            "Avg Inference Time per Sample Change: -98.91%\n",
            "Params Change: -99.84%\n",
            "Model Size Change: -99.84%\n",
            "\n",
            "--- Percentage Change (Person vs Teacher) ---\n",
            "RMSE Change: 108.01%\n",
            "Total Inference Time Change: -99.10%\n",
            "Avg Inference Time per Sample Change: -99.10%\n",
            "Params Change: -99.84%\n",
            "Model Size Change: -99.84%\n"
          ]
        }
      ]
    }
  ]
}