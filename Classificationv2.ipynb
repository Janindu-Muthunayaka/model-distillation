{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPx7ZfPoY1w/VvjJYHHZVO6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Janindu-Muthunayaka/model-distillation/blob/main/Classificationv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr5pC7ZyvkBw"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install torch torchvision numpy pandas\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# -----------------------------\n",
        "# Hyperparameters\n",
        "# -----------------------------\n",
        "epochs = 12\n",
        "batch_size = 64\n",
        "lr = 0.001\n",
        "temperature = 2.0\n",
        "alpha = 0.5\n",
        "\n",
        "# -----------------------------\n",
        "# Data Preparation\n",
        "# -----------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# -----------------------------\n",
        "# Teacher CNN\n",
        "# -----------------------------\n",
        "class TeacherCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(64*7*7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# -----------------------------\n",
        "# Student CNN (smaller)\n",
        "# -----------------------------\n",
        "class StudentCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(16*7*7, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# -----------------------------\n",
        "# Distillation Loss\n",
        "# -----------------------------\n",
        "def distillation_loss(student_logits, teacher_logits, labels, T=2.0, alpha=0.5):\n",
        "    hard_loss = F.cross_entropy(student_logits, labels)\n",
        "    soft_student = F.log_softmax(student_logits / T, dim=1)\n",
        "    soft_teacher = F.softmax(teacher_logits / T, dim=1)\n",
        "    soft_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (T * T)\n",
        "    return alpha * hard_loss + (1 - alpha) * soft_loss\n",
        "\n",
        "# -----------------------------\n",
        "# Training Functions\n",
        "# -----------------------------\n",
        "def train_model(model, train_loader, optimizer, criterion, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        if (epoch+1) % 3 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "def train_student_with_distillation(student, teacher, train_loader, optimizer, epochs, T=2.0, alpha=0.5):\n",
        "    teacher.eval()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                teacher_logits = teacher(x)\n",
        "            student_logits = student(x)\n",
        "            loss = distillation_loss(student_logits, teacher_logits, y, T, alpha)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        if (epoch+1) % 3 == 0:\n",
        "            print(f\"Student KD Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluation Functions\n",
        "# -----------------------------\n",
        "def evaluate_accuracy(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            outputs = model(x)\n",
        "            predicted = torch.argmax(outputs, dim=1)\n",
        "            correct += (predicted == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def evaluate_inference_time(model, test_loader, repeats=5):\n",
        "    model.eval()\n",
        "    times = []\n",
        "    with torch.no_grad():\n",
        "        for _ in range(repeats):\n",
        "            start = time.time()\n",
        "            for x, _ in test_loader:\n",
        "                _ = model(x)\n",
        "            end = time.time()\n",
        "            times.append(end - start)\n",
        "    avg_total_time = np.mean(times)\n",
        "    avg_per_sample = avg_total_time / len(test_loader.dataset)\n",
        "    return avg_total_time, avg_per_sample\n",
        "\n",
        "def evaluate_model_size(model):\n",
        "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    size_MB = num_params * 4 / (1024**2)\n",
        "    return num_params, size_MB\n",
        "\n",
        "# -----------------------------\n",
        "# Create Models\n",
        "# -----------------------------\n",
        "teacher = TeacherCNN()\n",
        "student = StudentCNN()\n",
        "person = StudentCNN()  # Same as student\n",
        "\n",
        "# -----------------------------\n",
        "# Optimizers\n",
        "# -----------------------------\n",
        "optimizer_teacher = optim.Adam(teacher.parameters(), lr=lr)\n",
        "optimizer_student = optim.Adam(student.parameters(), lr=lr)\n",
        "optimizer_person = optim.Adam(person.parameters(), lr=lr)\n",
        "\n",
        "# -----------------------------\n",
        "# Train Teacher\n",
        "# -----------------------------\n",
        "print(\"Training Teacher...\")\n",
        "train_model(teacher, train_loader, optimizer_teacher, nn.CrossEntropyLoss(), epochs)\n",
        "\n",
        "# -----------------------------\n",
        "# Train Student with KD\n",
        "# -----------------------------\n",
        "print(\"\\nTraining Student with KD...\")\n",
        "train_student_with_distillation(student, teacher, train_loader, optimizer_student, epochs, T=temperature, alpha=alpha)\n",
        "\n",
        "# -----------------------------\n",
        "# Train Person (Student architecture, normal training)\n",
        "# -----------------------------\n",
        "print(\"\\nTraining Person (same as Student, normal)...\")\n",
        "train_model(person, train_loader, optimizer_person, nn.CrossEntropyLoss(), epochs)\n",
        "\n",
        "# -----------------------------\n",
        "# Evaluate\n",
        "# -----------------------------\n",
        "models = {'Teacher': teacher, 'Student': student, 'Person': person}\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    acc = evaluate_accuracy(model, test_loader)\n",
        "    total_time, avg_time = evaluate_inference_time(model, test_loader)\n",
        "    params, size = evaluate_model_size(model)\n",
        "    results[name] = {\n",
        "        'Accuracy': acc,\n",
        "        'TotalTime': total_time,\n",
        "        'AvgTimePerSample': avg_time,\n",
        "        'Params': params,\n",
        "        'Size_MB': size\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# Display Results\n",
        "# -----------------------------\n",
        "for name, res in results.items():\n",
        "    print(f\"\\n{name} Metrics:\")\n",
        "    print(f\"Accuracy: {res['Accuracy']:.4f}\")\n",
        "    print(f\"Inference Time: {res['TotalTime']:.4f}s ({res['AvgTimePerSample']:.6f}s per sample)\")\n",
        "    print(f\"Parameters: {res['Params']}, Size: {res['Size_MB']:.4f} MB\")\n",
        "\n",
        "# -----------------------------\n",
        "# Compare % difference\n",
        "# -----------------------------\n",
        "def percent_change(student_val, teacher_val):\n",
        "    return ((student_val - teacher_val)/teacher_val)*100 if teacher_val !=0 else float('inf')\n",
        "\n",
        "print(\"\\n--- Percentage Change vs Teacher ---\")\n",
        "for name in ['Student', 'Person']:\n",
        "    print(f\"\\n{name} vs Teacher:\")\n",
        "    print(f\"Accuracy: {percent_change(results[name]['Accuracy'], results['Teacher']['Accuracy']):.2f}%\")\n",
        "    print(f\"Total Inference Time: {percent_change(results[name]['TotalTime'], results['Teacher']['TotalTime']):.2f}%\")\n",
        "    print(f\"Avg Time per Sample: {percent_change(results[name]['AvgTimePerSample'], results['Teacher']['AvgTimePerSample']):.2f}%\")\n",
        "    print(f\"Params: {percent_change(results[name]['Params'], results['Teacher']['Params']):.2f}%\")\n",
        "    print(f\"Model Size: {percent_change(results[name]['Size_MB'], results['Teacher']['Size_MB']):.2f}%\")\n"
      ]
    }
  ]
}